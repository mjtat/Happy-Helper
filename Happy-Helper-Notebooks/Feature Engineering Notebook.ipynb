{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to feature engineering. ##\n",
    "\n",
    "**In this notebook, I show some examples of feature engineering I did for the text.** I tried a bunch of different things: filtering out text that only had a mention of anxiety and/or depression, adding additional keywords (such associated with symptoms of either) or excluding different keywords (such as excluding depression from texts about anxiety). \n",
    "\n",
    "I ended up landing on the following method: Take texts that mention some keywords associated with anxiety and depression (e.g., the words anxiety or depression themselves, a symptom or two, and the mention of therapy). For the \"other\" category, I ended up using four unrelated subreddits, and took text examples that did not mention either depression or anxiety.\n",
    "\n",
    "There are a few things I would like to do in the future.\n",
    "* Dive in deeper into feature engineering. For example, not all texts are made the same. Some texts may detail an episode of depression, some might talk solely about a therapist, while another celebrates getting over depression. I would likely explore more methods of topic modeling to look for these features (e.g., Latent Semantic Analysis, Latent Dirchelet Allocation).\n",
    "\n",
    "* I might restrict word count to be greater than some number. As you might realize, posts can be quite short, or long. Longer posts may have greater details, and thus, be better suited for classification than shorter posts (given that text is generally sparse, short text would be very sparse!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import all the csvs, which originally was taken from the google bigquery database.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anxiety = pd.read_csv('reddit_anxiety.csv')\n",
    "depression = pd.read_csv('reddit_depression.csv')\n",
    "news = pd.read_csv('reddit_news.csv')\n",
    "cute = pd.read_csv('reddit_cute.csv')\n",
    "funny = pd.read_csv('reddit_funny.csv')\n",
    "med = pd.read_csv('reddit_medicine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter out specific texts with keywords for 'anxiety' posts.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anxiety = anxiety[anxiety['selftext'].str.contains('anx|pani|ther')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do the same for depression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depression = depression[depression['selftext'].str.contains('depres|lon|ther')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set those dataframes into a list, concatenate them all together.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = [news, cute, funny, med]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "other = pd.concat(frames)\n",
    "other = other.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set the 'other' dataframe to find text that has no mention of anxiety or depression.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "other = other[~other['selftext'].str.contains('anx|depres')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write all the data to csvs for later importing and modeling.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "depression.to_csv('reddit_depress_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "anxiety.to_csv('reddit_anxiety_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other.to_csv('other.csv')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
